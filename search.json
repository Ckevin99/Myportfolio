[
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "story_telling.html#title-2-header",
    "href": "story_telling.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "projects.html#repo-for-all-my-projects",
    "href": "projects.html#repo-for-all-my-projects",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "Projects/project5.html",
    "href": "Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#elevator-pitch",
    "href": "Projects/project5.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-1",
    "href": "Projects/project5.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nCOPY PASTE QUESTION|TASK 1 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q1 chart .cell execution_count=4}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q1 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=5}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-2",
    "href": "Projects/project5.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nCOPY PASTE QUESTION|TASK 2 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q2 chart .cell execution_count=7}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q2 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=8}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-3",
    "href": "Projects/project5.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nCOPY PASTE QUESTION|TASK 3 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q3 chart .cell execution_count=10}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q3 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=11}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project3.html",
    "href": "Projects/project3.html",
    "title": "Client Report - Project 3",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ncon = sqlite3.connect(\"lahmansbaseballdb.sqlite\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#elevator-pitch",
    "href": "Projects/project3.html#elevator-pitch",
    "title": "Client Report - Project 3",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ncon = sqlite3.connect(\"lahmansbaseballdb.sqlite\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-1",
    "href": "Projects/project3.html#questiontask-1",
    "title": "Client Report - Project 3",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nWrite an SQL query to create a new dataframe about baseball players who attended BYU-Idaho. The new table should contain five columns: playerID, schoolID, salary, and the yearID/teamID associated with each salary. Order the table by salary (highest to lowest) and print out the table in your report.\nUsing as parameter players who played on byui, 3 players were finded, one of them doesn’t have data from salaries of teams\n\n\nRead and format data\n# Include and execute your code here\nc=  \"\"\"\nSELECT DISTINCT cp.PlayerID\n, cp.schoolID\n, s.salary\n, s.yearID\n, s.team_ID\n\nFROM collegeplaying AS cp\nLEFT join salaries AS s \nON s.PlayerID = cp.PlayerID\n\n\nWHERE cp.schoolID = \"idbyuid\"\ngroup by cp.playerID\nORDER BY s.salary DESC\n\n\n\n\n\n\n\"\"\"\n\npd.read_sql(c, con)\n\n\n\n\n\n\n\n\n\nplayerID\nschoolID\nsalary\nyearID\nteam_ID\n\n\n\n\n0\nlindsma01\nidbyuid\n380000.0\n2007.0\n2546.0\n\n\n1\nstephga01\nidbyuid\n150000.0\n1997.0\n2258.0\n\n\n2\ncatetr01\nidbyuid\nNaN\nNaN\nNaN",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-2",
    "href": "Projects/project3.html#questiontask-2",
    "title": "Client Report - Project 3",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nA - Write an SQL query that provides playerID, yearID, and batting average for players with at least 1 at bat that year. Sort the table from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report.\nUsing a least one batting is not a good parameter because players that just had one at bat and got a hit will be 100% percentage, even if in others years they had bad ratios\n\n\nRead and format data\nsqlq = \"\"\"\nSELECT\n  playerID\n, yearID\n, H\n, AB\n, H*100/AB*1.0 as \"Average hits %\" \nFROM \nbatting\nwhere AB &gt;=1\norder by H*100/AB*1.0 desc,playerID asc\nlimit 5\n\n\n\n\"\"\"\n\n\npd.read_sql(sqlq, con)\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nH\nAB\nAverage hits %\n\n\n\n\n0\naberal01\n1957\n1\n1\n100.0\n\n\n1\nabernte02\n1960\n1\n1\n100.0\n\n\n2\nabramge01\n1923\n1\n1\n100.0\n\n\n3\nacklefr01\n1964\n1\n1\n100.0\n\n\n4\nalanirj01\n2019\n1\n1\n100.0\n\n\n\n\n\n\n\nUsing a least 10 as parameter created a more trustfull data about the average hits, but it is a small sample to take conclusion of players with the best hits ratio\nB - Use the same query as above, but only include players with at least 10 at bats that year. Print the top 5 results.\nUsing a least 10 as parameter created a more trustfull data about the average hits, but it is a small sample to take conclusion of players with the best hits ratio.\n\n\nShow the code\nsqlq = \"\"\"\nSELECT\n  playerID\n, yearID\n, H\n, AB\n, H*100/AB*1.0 as \"Average hits %\" \nFROM \nbatting\nwhere AB &gt;=10\norder by H*100/AB*1.0 desc,playerID asc\nlimit 5\n\n\n\n\"\"\"\n\n\npd.read_sql(sqlq, con)\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nH\nAB\nAverage hits %\n\n\n\n\n0\nnymanny01\n1974\n9\n14\n64.0\n\n\n1\ncarsoma01\n2013\n7\n11\n63.0\n\n\n2\naltizda01\n1910\n6\n10\n60.0\n\n\n3\njohnsde01\n1975\n6\n10\n60.0\n\n\n4\nsilvech01\n1948\n8\n14\n57.0\n\n\n\n\n\n\n\nC - Now calculate the batting average for players over their entire careers (all years combined). Only include players with at least 100 at bats, and print the top 5 results.\nThis data was gathered by grouping all the data of all years, so we have a trusted average hits of players, the data showed that the bests players has a average of 35% of at bat / hits.\n\n\nShow the code\nsqlq = \"\"\"\nSELECT\n  playerID\n, sum(H) as \"total H\"\n, sum(AB) as \"Total AB\"\n, (sum(H)*100/sum(AB)*1.0) as \"Average hits %\" \nFROM \nbatting\ngroup by playerID\nhaving sum(AB) &gt;=100\n\nORDER BY (sum(H)*100/sum(AB)*1.0) DESC,playerID asc\nlimit 5\n\n\n\n\n\n\"\"\"\n\n\npd.read_sql(sqlq, con)\n\n\n\n\n\n\n\n\n\nplayerID\ntotal H\nTotal AB\nAverage hits %\n\n\n\n\n0\ncobbty01\n4189\n11436\n36.0\n\n\n1\nbarnero01\n860\n2391\n35.0\n\n\n2\nhornsro01\n2930\n8173\n35.0\n\n\n3\njacksjo01\n1772\n4981\n35.0\n\n\n4\nkingst01\n96\n272\n35.0",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-3",
    "href": "Projects/project3.html#questiontask-3",
    "title": "Client Report - Project 3",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nPick any two baseball teams and compare them using a metric of your choice (average salary, home runs, number of wins, etc). Write an SQL query to get the data you need, then make a graph using Plotly Express to visualize the comparison. What do you learn?\nThe New York Yankees and Boston Red Sox teams has a very interesting pattern, the first one expend more in the wages and consequently has more wins rate, the first one had wage expenses 32 % greater than the second one and 5.7% more winrate, which is 0.17% more winrate for each 1% more in wage expenses. \n\n\nRead and format data\nquery = \"\"\"\nselect \nt.name\n, round((sum(salary)/1000000),2) as \"Wage Expenses in Millions\"\n, round((sum(W)*1.0/(sum(W)+sum(L))*100),2) as \"Win ratio\"\nfrom teams t\njoin salaries as s \nON s.team_ID =  t.ID\ngroup by t.name\norder by \"Win ratio\" desc\n\n\n\n\"\"\"\n\n\nnewdf = pd.read_sql(query, con)\n\n\nfig = px.scatter(newdf, x=\"Wage Expenses in Millions\", y=\"Win ratio\", title= \"Total Wage expenses over 31 years\" ).update_traces(marker=dict(color='black')).update_layout(title_x=0.45)\n\nnewdff = newdf[(newdf[\"name\"] == \"New York Yankees\") | (newdf[\"name\"] == \"Boston Red Sox\")]\n\nhighlight_fig = px.scatter(newdff, x=\"Wage Expenses in Millions\", y=\"Win ratio\", color= \"name\")\n                   \n\n# Add the highlighted data point to the original plot\nfig.add_trace(highlight_fig.data[0])\nfig.add_trace(highlight_fig.data[1])\nfig.update(layout_yaxis_range = [30,75])\nfig.update(layout_xaxis_range = [600,4000])\n\nfig.show()\n\n\n                                                \n\n\n_Comparing the teams win rate and wages expenses we see a clearly relation between the amount of wins and the total invested on these teams. the trendline for this data can be found using the formula: y = 46.093e5E-05x. Using this formula, to have a win rate of 75% you should have a budget of 10000 Millions in the period, whick is almost 3 times the expenses of New York Yankees, with a win rate of 56%.\n(75%=46.093EXP(0.0000510000)) _",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project1.html",
    "href": "Projects/project1.html",
    "title": "Client Report - Project 1",
    "section": "",
    "text": "With data of the name usage over 100 years, I compared it with my name, and I discovered an increase of 9000% in 1940 over 20 years. Comparing the name britanny, I discovered that 9.04% of all people called britanny are 34 years old. The names Mary, Martha, Paul, and Peter over 80 years reduced your utilization by 84%. Analyzing the utilization of the name Rocky with the release of the movie Rocky doesn’t look to have a correlation with the name usage.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#elevator-pitch",
    "href": "Projects/project1.html#elevator-pitch",
    "title": "Client Report - Project 1",
    "section": "",
    "text": "With data of the name usage over 100 years, I compared it with my name, and I discovered an increase of 9000% in 1940 over 20 years. Comparing the name britanny, I discovered that 9.04% of all people called britanny are 34 years old. The names Mary, Martha, Paul, and Peter over 80 years reduced your utilization by 84%. Analyzing the utilization of the name Rocky with the release of the movie Rocky doesn’t look to have a correlation with the name usage.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#question-1",
    "href": "Projects/project1.html#question-1",
    "title": "Client Report - Project 1",
    "section": "QUESTION 1",
    "text": "QUESTION 1\nHow does your name at your birth year compare to its use historically?\nKevin is a name that, in the US, started to be used around 1940. In 20 years, the name utilization increased by 9000%, reaching its peak in 1963. After this date, the name tends to be less used.\n\n\nRead and format data\n# Include and execute your code here\nx =df.loc[(df[\"name\"]==\"Kevin\")]\n# xa =df.loc[df[\"name\"]==\"Oliver\"]\n# print(xa)\nchart2 = px.line(x, \nx=\"year\", y=\"Total\",\ntitle = \"The use of the name Kevin in the last 100 years\").update_layout(title_x=0.45).add_vline(x=1963, line_width=2, line_dash=\"dash\", annotation_text=\"Peak\", line_color=\"red\").update_traces(line_color='darkblue')\n\nchart2.show()\n\n# counts = df['name'].value_counts()\n# qwe = xa[\"UT\"].sum()\n# print(qwe)\n#print(counts[\"Oliver\"])",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-2",
    "href": "Projects/project1.html#questiontask-2",
    "title": "Client Report - Project 1",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nIf you talked to someone named Brittany on the phone, what is your guess of his or her age? What ages would you not guess?\nIf I would guess an age, I would say 34 years old or around it, because that is the peak of the number of names. I would not say any age less than 23 years old or more than 41 years old. In this range, we will have 90% fewer people than people around 34 years old..\n\n\nRead and format data\n# Include and execute your code here\nx =df.loc[(df[\"name\"]==\"Brittany\")]\nchart1 = px.line(x, \nx=\"year\", y=\"Total\",\ntitle = \"The use of the name Brittany in the last 100 years\").update_layout(title_x=0.45).add_vline(x=1990, line_width=2, line_dash=\"dash\", annotation_text=\"Peak\", line_color=\"red\").update_traces(line_color='darkblue')\n\n\nchart1.show()\n\n\n                                                \n\n\nAccording to the pie chart below, if you guess 34 years old, you would have a percentage of 9.04% of being right.\n\n\nShow the code\ntotalNames =x['Total'].sum()\n\n\nlabels = ['Total Names','Names in 1990',]\nvalues = [totalNames, 32562]\n\nfig = go.Figure(data=[go.Pie(labels=labels, values=values,)])\nfig.show()",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-3",
    "href": "Projects/project1.html#questiontask-3",
    "title": "Client Report - Project 1",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names. What trends do you notice?\nThey had a great surge on 1915, followed by a slight decrease in utilization from 1928 until 1936, when they started to appear in a huge amount again. In 1954, it started to diminish, and this trend was followed until the last data we had, which is from 2014. During the entire period, a total of 4826973 people received one of these names.\n\n\nShow the code\nx =df.query(\"name == ['Mary','Martha','Peter','Paul']\")\nz =x['Total'].sum()\nchart1 = px.line(x, \nx=\"year\", y=\"Total\",\ntitle = \"Utilization of the names Mary, Martha, Peter, and Paul over 100 years\", color='name').update_layout(title_x=0.45).add_vline(x=1950, line_width=2, line_dash=\"dash\", annotation_text=\"Peak\", line_color=\"DARKBLUE\")\n\nchart1.show()",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-4",
    "href": "Projects/project1.html#questiontask-4",
    "title": "Client Report - Project 1",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage?\nIt doesn’t like to have a strict relationship between the event of the name usage and the release of the movie, the name started to rise even before the movie, and the name usage had a similar pattern before. \n\n\nShow the code\na =df.query(\"name == 'Rocky'\")\n\nchart3 = px.line(a, \nx=\"year\", y=\"Total\",\ntitle = \"Rocky name usage over 100 years\", color='name').update_layout(title_x=0.45).add_vline(x=1976, line_width=2, line_dash=\"dash\", annotation_text=\"Release\", line_color=\"red\").update_traces(line_color='darkblue')\n\nchart3.show()",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html#title-2-header",
    "href": "index.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html#title-2-header",
    "href": "full_stack.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "Projects/project2.html",
    "href": "Projects/project2.html",
    "title": "Client Report - Project 2",
    "section": "",
    "text": "In this project, I used different approaches to handle data with non-standardized NaN and built consistent data. In this analysis, San fracisco (SFO) has had most chance of having a delay in the last years. I also analyzed the “best” delays, and Salt Lake and San Diego airports had the shortest delay times. About the best month to travel, if delay is the unique parameter, September and November are the best months to travel, with 37% less chance of having delay compared to December. Another interesting thing is that weather is the main reason for delays (56%). \n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_json(\"https://raw.githubusercontent.com/byuidatascience/data4missing/master/data-raw/flights_missing/flights_missing.json\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#elevator-pitch",
    "href": "Projects/project2.html#elevator-pitch",
    "title": "Client Report - Project 2",
    "section": "",
    "text": "In this project, I used different approaches to handle data with non-standardized NaN and built consistent data. In this analysis, San fracisco (SFO) has had most chance of having a delay in the last years. I also analyzed the “best” delays, and Salt Lake and San Diego airports had the shortest delay times. About the best month to travel, if delay is the unique parameter, September and November are the best months to travel, with 37% less chance of having delay compared to December. Another interesting thing is that weather is the main reason for delays (56%). \n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_json(\"https://raw.githubusercontent.com/byuidatascience/data4missing/master/data-raw/flights_missing/flights_missing.json\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-1",
    "href": "Projects/project2.html#questiontask-1",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nFix all of the varied missing data types in the data to be consistent (all missing values should be displayed as “NaN”).\nIn the dataframe were found different “versions” of NaN. Some of them were represented as an integer (-999) or a string (“nan”). All of them were converted to the default NaN.\n\n\nRead and format data\n# Include and execute your code here\ndf[\"month\"].replace(\"n/a\", np.nan, inplace=True)\n\ndf[\"num_of_delays_late_aircraft\"].replace(-999, np.nan, inplace=True)\ndfdisplay =df.drop('airport_name', axis=1)\ndf[\"month\"].replace(\"Febuary\", \"February\", inplace=True)\n\n\nAdditionally, the dataframe had values like “+1500” that needed to be standardized before making any calculations. To see the best option, I used a function to see the max value, and it returned 998, so I thought that the 1500 decision was wrong, but I noticed that some numers were formatted as strings, which was the reason of just 998. For this reason, I replaced the value 1500+ to 1500 and iterated over all values to turn them into integers.\nOne row from the dataframe to JSON format.\n\n\nShow the code\ndf[\"num_of_delays_carrier\"].replace(\"1500+\",1500,inplace=True)\n\nfor i in range(len(df)):\n   x=  df[\"num_of_delays_carrier\"].values[i]\n   df[\"num_of_delays_carrier\"].values[i]= int(x)\n\ndfdisplay =df.drop('airport_name', axis=1)\nlistjson = dfdisplay.to_json(orient=\"records\", lines=True).splitlines()\nlistjson[0]\n\n\n'{\"airport_code\":\"ATL\",\"month\":\"January\",\"year\":2005.0,\"num_of_flights_total\":35048,\"num_of_delays_carrier\":1500,\"num_of_delays_late_aircraft\":null,\"num_of_delays_nas\":4598,\"num_of_delays_security\":10,\"num_of_delays_weather\":448,\"num_of_delays_total\":8355,\"minutes_delayed_carrier\":116423.0,\"minutes_delayed_late_aircraft\":104415,\"minutes_delayed_nas\":207467.0,\"minutes_delayed_security\":297,\"minutes_delayed_weather\":36931,\"minutes_delayed_total\":465533}'\n\n\nBefore going to the calculations, I made some decisions about filling in the NaN values. I started handling the missing months, even using ffill(), some months stayed with 10 or 12 counts.\n\n\nShow the code\ndf[\"month\"] = df[\"month\"].ffill()\npd.crosstab(df.airport_code,df.month).head(1)\n\n\n\n\n\n\n\n\nmonth\nApril\nAugust\nDecember\nFebruary\nJanuary\nJuly\nJune\nMarch\nMay\nNovember\nOctober\nSeptember\n\n\nairport_code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nATL\n11\n11\n10\n11\n12\n11\n11\n10\n11\n11\n12\n11\n\n\n\n\n\n\n\nKnowing that they are following the order of the ID (the firsts are the oldest), I used it as a parameter to change the wrong months.\n\n\nShow the code\n#I changed the value of id 490 in october to november, because are two of these values and the 490 was the greater\ndf[\"month\"].values[490] = df[\"month\"].values[490] =\"November\"\n# I did the same thing to this one, one data were repeated with 2 ids differentes.\ndf[\"month\"].values[329] = df[\"month\"].values[329] =\"December\"\n#In that one we had 2 n/a, so to decide what I would keep I notice a pattern that each 84 numbers a row of the same month would appear, 343 been out of this scope was removed to February\ndf[\"month\"].values[343] = df[\"month\"].values[343] =\"February\"\n# In the end stayed the value 343 and the value 350, February was following a odd pattern, so 350 would not be part of it.\ndf[\"month\"].values[350] = df[\"month\"].values[350] =\"March\"\n\n\ndf[\"year\"] = df[\"year\"].ffill()\n\n\n\n\nShow the code\npd.crosstab(df.airport_code,df.month).head(1)\n\n\n\n\n\n\n\n\nmonth\nApril\nAugust\nDecember\nFebruary\nJanuary\nJuly\nJune\nMarch\nMay\nNovember\nOctober\nSeptember\n\n\nairport_code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nATL\n11\n11\n11\n11\n11\n11\n11\n11\n11\n11\n11\n11\n\n\n\n\n\n\n\nThe missing values of the minutes columns are included in the total minutes, so we can get it using a basic equation, but I had more than one column missing data in the same row, so before making an equation, I needed to handle these values by making a prediction using the same month for the near years. Because of the range of 10 years, the average would disturb the data, so I didn’t use it.\n\n\nShow the code\ndfdisplay = df[(df[\"minutes_delayed_nas\"].isna()) & (df[\"minutes_delayed_carrier\"].isna())]\ndfdisplay =df.drop('airport_name', axis=1)\ndfdisplay.head(2)\n\n\n\n\n\n\n\n\n\nairport_code\nmonth\nyear\nnum_of_flights_total\nnum_of_delays_carrier\nnum_of_delays_late_aircraft\nnum_of_delays_nas\nnum_of_delays_security\nnum_of_delays_weather\nnum_of_delays_total\nminutes_delayed_carrier\nminutes_delayed_late_aircraft\nminutes_delayed_nas\nminutes_delayed_security\nminutes_delayed_weather\nminutes_delayed_total\n\n\n\n\n0\nATL\nJanuary\n2005.0\n35048\n1500\nNaN\n4598\n10\n448\n8355\n116423.0\n104415\n207467.0\n297\n36931\n465533\n\n\n1\nDEN\nJanuary\n2005.0\n12687\n1041\n928.0\n935\n11\n233\n3153\n53537.0\n70301\n36817.0\n363\n21779\n182797\n\n\n\n\n\n\n\n\n\nShow the code\nfor i in range(len(df)):\n    if (str(df[\"minutes_delayed_carrier\"].values[i]) ==\"nan\") and (str(df[\"minutes_delayed_nas\"].values[i])==\"nan\"):\n        year= df[\"year\"].values[i]\n        air = df[\"airport_code\"].values[i]\n        month =df[\"month\"].values[i]\n        \n        prev = df.loc[((df[\"year\"])==year-1) & (df[\"airport_code\"]==air) & (df[\"month\"]==month)]\n        nextt = df.loc[((df[\"year\"])==year+1) & (df[\"airport_code\"]==air) & (df[\"month\"]==month)]\n\n        newvaluecarrier = (prev[\"minutes_delayed_carrier\"].values[0]+nextt[\"minutes_delayed_carrier\"].values[0])/2\n\n        prev_nas = df.loc[((df[\"year\"])==year+2) & (df[\"airport_code\"]==air) & (df[\"month\"]==month)]\n\n        newvaluenas = (prev_nas[\"minutes_delayed_nas\"].values[0]+nextt[\"minutes_delayed_nas\"].values[0])/2\n\n\n\n        df[\"minutes_delayed_carrier\"].values[i]= newvaluecarrier\n\n\n\n\nShow the code\nfor i in range(len(df)):\n    carrier = 0\n    \n    \n    if str(df[\"minutes_delayed_carrier\"].values[i]) == \"nan\":\n      \n      total = df[\"minutes_delayed_total\"].values[i]\n\n      weather = df[\"minutes_delayed_weather\"].values[i]\n      security = df[\"minutes_delayed_security\"].values[i]\n\n      nas = df[\"minutes_delayed_nas\"].values[i]\n      aircraft = df[\"minutes_delayed_late_aircraft\"].values[i]\n      \n      carrier = total-weather-security-nas-aircraft\n      \n\n      \n      \n      df[\"minutes_delayed_carrier\"].values[i]= carrier\n\n    if str(df[\"minutes_delayed_nas\"].values[i]) == \"nan\":\n      nas = 0\n      total = df[\"minutes_delayed_total\"].values[i]\n\n      weather = df[\"minutes_delayed_weather\"].values[i]\n      security = df[\"minutes_delayed_security\"].values[i]\n\n      carrier = df[\"minutes_delayed_carrier\"].values[i]\n      aircraft = df[\"minutes_delayed_late_aircraft\"].values[i]\n      \n      nas = total-weather-security-aircraft-carrier\n\n      df[\"minutes_delayed_nas\"].values[i]=nas",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-2",
    "href": "Projects/project2.html#questiontask-2",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nWhich airport has the worst delays?\nAccording to the graphics, San francisco has most delays of all airport, having more than one in 4 flights delayed. San fracisco and Chicago has the most wait time of all airports analyzed, with Chicago having average of 68 minutes and 63 minutes in San francisco. The airports of San Diego and Salt Lake had the lowest delays, with 47.2 and 49.34, respectively. It is not asking which has more delays, but what has the worst delays, that is the reason that I used delay time as a parameter.\n\n\nRead and format data\n# Include and execute your code here\n\n#It is asking what airport has the worsts delays and not more delay.\ntable2 = df[[\"airport_code\",\"num_of_flights_total\",\"num_of_delays_total\",\"minutes_delayed_total\"]]\ntable2sum = table2.groupby(\"airport_code\").agg(flights_total= (\"num_of_flights_total\", \"sum\"), flight_delayed= ((\"num_of_delays_total\", \"sum\")), hours_delayed= (\"minutes_delayed_total\", \"mean\"))\ntable2sum[\"hours_delayed\"]= round(table2sum[\"hours_delayed\"]/60)\ntable2sum.insert(2, \" flights/delays %\", value=(table2sum.flight_delayed/table2sum.flights_total)*100 )\n\ntable2sum\n\n\n\n\n\n\n\n\n\nflights_total\nflight_delayed\nflights/delays %\nhours_delayed\n\n\nairport_code\n\n\n\n\n\n\n\n\nATL\n4430047\n902443\n20.370958\n6816.0\n\n\nDEN\n2513974\n468519\n18.636589\n3178.0\n\n\nIAD\n851571\n168467\n19.783083\n1298.0\n\n\nORD\n3597588\n830825\n23.093945\n7116.0\n\n\nSAN\n917862\n175132\n19.080428\n1045.0\n\n\nSFO\n1630945\n425604\n26.095546\n3352.0\n\n\nSLC\n1403384\n205160\n14.618950\n1278.0\n\n\n\n\n\n\n\n\n\nShow the code\nnewdfref3 = df.groupby('airport_code').agg(delays = ('num_of_delays_total', 'sum'),totalf =('num_of_flights_total', 'sum')).reset_index()\nnewdfref3.insert(3,\"%\", value=(newdfref3.delays/newdfref3.totalf)*100)\n\nchart22 = px.bar(newdfref3, x=\"airport_code\", y=\"%\", color=\"airport_code\", title=\"Average delay chance\", text_auto=True).update_layout(title_x=0.45)\n\n\nchart22\n\n\n                                                \n\n\n\n\nShow the code\nnewdf = df[[\"airport_code\",\"minutes_delayed_total\",\"num_of_delays_total\"]]\nnewdf.insert(3,\"minutes_delayed_per_flight\", value= ((newdf[\"minutes_delayed_total\"]/newdf[\"num_of_delays_total\"])))\n\nnewdfref = newdf.groupby('airport_code').agg(flights = ('minutes_delayed_total', 'sum'),delays =('num_of_delays_total', 'sum')).reset_index()\nnewdfref.insert(3,\"Minutes\", value=newdfref.flights/newdfref.delays)\n\nchart2 = px.bar(newdfref, x=\"airport_code\", y=\"Minutes\", color=\"airport_code\", title= \"Average delay time on flights\", text_auto=True)\nchart2.update_layout(title_x=0.45)\n\n\n                                                \n\n\nEven San Diego airport having 4% less wait time than Salt Lake airport in delays, the San diego aiport has 30% more chance of having a delay. Which would make the salt lake airport, the airport with less delay\n\n\nShow the code\ndffilter = df.query(\"airport_code == ['SAN','ORD','SLC']\")\nnewdfref3 = dffilter.groupby('airport_code').agg(delays = ('num_of_delays_total', 'sum'),totalf =('num_of_flights_total', 'sum')).reset_index()\nnewdfref3.insert(3,\"%\", value=(newdfref3.delays/newdfref3.totalf)*100)\n\nchart22 = px.bar(newdfref3, x=\"airport_code\", y=\"%\", color=\"airport_code\", title=\"Average delay chance\", text_auto=True).update_layout(title_x=0.45)\n\n\nchart22",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-3",
    "href": "Projects/project2.html#questiontask-3",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nWhat is the best month to fly if you want to avoid delays of any length?\nWhen avoid delay is the unique parameter, the best metrics is the chances of having delay, no matter if one will wait 2 hours and another 30 minutes. September is the best month to fly, with 16.45% of chance for delay, which is 37% less when compared to December. November also has a low percentage, at 16.66%.\n\n\nRead and format data\n# Include and execute your code here\nnewdf2 = df\n\nnewdfref2 = newdf2.groupby('month').agg(delays = ('num_of_delays_total', 'sum'),totalf =('num_of_flights_total', 'sum')).reset_index()\nnewdfref2.insert(2,\"%\", value=(newdfref2.delays/newdfref2.totalf)*100)\n\n\nmonth_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\nnewdfref2[\"month\"] = pd.Categorical(newdfref2[\"month\"],categories= month_order,ordered=True)\n\nnewdfref2.sort_values(by=\"month\", inplace=True)\n\n\n\npx.bar(newdfref2, x=\"month\", y=\"%\", color=\"month\",title= \"Delay chance x Months\", text_auto=True).update_layout(title_x=0.45)",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-4",
    "href": "Projects/project2.html#questiontask-4",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nAccording to the BTS website, the “Weather” category only accounts for severe weather delays. Mild weather delays are not counted in the “Weather” category, but are actually included in both the “NAS” and “Late-Arriving Aircraft” categories. Your job is to create a new column that calculates the total number of flights delayed by weather (both severe and mild).\nAccording to this data, weather is the principal reason for late flights, on average, it is responsible for 56% of all late flights. Many of these delays are not caused for severe weather.\nThe aircraft late has NaN values\n\n\nShow the code\ndf.head(1)\n\n\n\n\n\n\n\n\n\nairport_code\nairport_name\nmonth\nyear\nnum_of_flights_total\nnum_of_delays_carrier\nnum_of_delays_late_aircraft\nnum_of_delays_nas\nnum_of_delays_security\nnum_of_delays_weather\nnum_of_delays_total\nminutes_delayed_carrier\nminutes_delayed_late_aircraft\nminutes_delayed_nas\nminutes_delayed_security\nminutes_delayed_weather\nminutes_delayed_total\n\n\n\n\n0\nATL\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\nJanuary\n2005.0\n35048\n1500\nNaN\n4598\n10\n448\n8355\n116423.0\n104415\n207467.0\n297\n36931\n465533\n\n\n\n\n\n\n\nInstead of just fulfilling the aircraft late NaNs with the average, I notice that the dataframe already contains this data included in total. so I had all the values necessary to do an equation. So I take the total and subtract all other lates to find the aircraft late.\n\n\nShow the code\nfor i in range(len(df)):\n    aircraft = 0\n    \n    \n    if str(df[\"num_of_delays_late_aircraft\"].values[i]) == \"nan\":\n      \n      total = df[\"num_of_delays_total\"].values[i]\n\n      weather = df[\"num_of_delays_weather\"].values[i]\n      security = df[\"num_of_delays_security\"].values[i]\n\n      nas = df[\"num_of_delays_nas\"].values[i]\n      carrier = df[\"num_of_delays_carrier\"].values[i]\n      \n      aircraft = total-weather-security-nas-carrier \n      \n\n      \n      df[\"num_of_delays_late_aircraft\"].values[i]= aircraft\ndfdisplay =df.drop('airport_name', axis=1)\ndfdisplay.head(1)\n\n\n\n\n\n\n\n\n\nairport_code\nmonth\nyear\nnum_of_flights_total\nnum_of_delays_carrier\nnum_of_delays_late_aircraft\nnum_of_delays_nas\nnum_of_delays_security\nnum_of_delays_weather\nnum_of_delays_total\nminutes_delayed_carrier\nminutes_delayed_late_aircraft\nminutes_delayed_nas\nminutes_delayed_security\nminutes_delayed_weather\nminutes_delayed_total\n\n\n\n\n0\nATL\nJanuary\n2005.0\n35048\n1500\n1799.0\n4598\n10\n448\n8355\n116423.0\n104415\n207467.0\n297\n36931\n465533\n\n\n\n\n\n\n\n\n\nRead and format data\n# Include and execute your code here\nnewdf3 = df\n\nnewdf3.insert(6, \"severe\", value=df.num_of_delays_weather)\n\nnewdf3.insert(7, \"mild\", value=df.num_of_delays_late_aircraft*0.3)\n\nnewdf3.insert(8, \"mild_nas\", value=np.where(df.month.isin([\"'April', 'May', 'June', 'July', 'August'\"]),df.num_of_delays_nas *0.4,\ndf.num_of_delays_nas *0.65))\n\nnewdf3.insert(9, \"Total_weather\", value= newdf3.severe + newdf3.mild + newdf3.mild_nas)\n\nnewdf3.insert(10, \"Proportion_late_weather\", value= newdf3.Total_weather/newdf3.num_of_delays_total)\n\nnewdf3.insert(10, \"Proportion_total_lweather\", value= newdf3.Total_weather/newdf3.num_of_flights_total)\n\n\nnewdf3 = newdf3[[\"airport_code\",\"month\",\"year\",\"severe\",    \"mild\", \"mild_nas\",\"num_of_flights_total\",\"num_of_delays_total\",\"Total_weather\",\"Proportion_late_weather\",\"Proportion_total_lweather\"]]\n\nnewdf3.head()\n\n\n\n\n\n\n\n\n\nairport_code\nmonth\nyear\nsevere\nmild\nmild_nas\nnum_of_flights_total\nnum_of_delays_total\nTotal_weather\nProportion_late_weather\nProportion_total_lweather\n\n\n\n\n0\nATL\nJanuary\n2005.0\n448\n539.7\n2988.70\n35048\n8355\n3976.40\n0.475931\n0.113456\n\n\n1\nDEN\nJanuary\n2005.0\n233\n278.4\n607.75\n12687\n3153\n1119.15\n0.354948\n0.088212\n\n\n2\nIAD\nJanuary\n2005.0\n61\n317.4\n581.75\n12381\n2430\n960.15\n0.395123\n0.077550\n\n\n3\nORD\nJanuary\n2005.0\n306\n676.5\n3519.75\n28194\n9178\n4502.25\n0.490548\n0.159688\n\n\n4\nSAN\nJanuary\n2005.0\n56\n204.0\n414.70\n7283\n1952\n674.70\n0.345645\n0.092640",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-5",
    "href": "Projects/project2.html#questiontask-5",
    "title": "Client Report - Project 2",
    "section": "QUESTION|TASK 5",
    "text": "QUESTION|TASK 5\nUsing the new weather variable calculated above, create a barplot showing the proportion of all flights that are delayed by weather at each airport. Discuss what you learn from this graph.\n_With 4.63%, Salt Lake Airport is the most likely airport to don’t be delayed for weather reasons, San Francisco is the most likely with 11.04%, other airports have an average of 7.5%.__\n\n\nRead and format data\n# Include and execute your code here\ndfquestion5 = newdf3.groupby('airport_code').agg(delays = ('Total_weather', 'sum'),totalf =('num_of_flights_total', 'sum')).reset_index()\ndfquestion5.insert(3,\"%\", value=(dfquestion5.delays/dfquestion5.totalf)*100)\nchart5 = px.bar(dfquestion5,\"airport_code\",\"%\", color=\"airport_code\",title= \"Percentage of delays by weather per airport\", text_auto=True).update_layout(title_x=0.45)\n\nchart5",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project4.html",
    "href": "Projects/project4.html",
    "title": "Client Report - Project 4",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ncon = sqlite3.connect('lahmansbaseballdb.sqlite')\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#elevator-pitch",
    "href": "Projects/project4.html#elevator-pitch",
    "title": "Client Report - Project 4",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ncon = sqlite3.connect('lahmansbaseballdb.sqlite')\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-1",
    "href": "Projects/project4.html#questiontask-1",
    "title": "Client Report - Project 4",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nWrite an SQL query to create a new dataframe about baseball players who attended BYU-Idaho. The new table should contain five columns: playerID, schoolID, salary, and the yearID/teamID associated with each salary. Order the table by salary (highest to lowest) and print out the table in your report.\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\np = \"\"\"\n\nSELECT H, AB, YEARiD\nFROM batting\nLIMIT 2\n\"\"\"\n\nx = \"\"\"\nselect Playerid,AB/ H, H*1.0  / AB*1.0 ,yearid\nFrom batting \nwhere PlayerID = \"addybo01\" and\nYearID = 1871\n\n\"\"\"\npd.read_sql_query(p, con)\n\npd.read_sql_query(x, con)\n\n\n\n\n\n\n\n\n\nplayerID\nAB/ H\nH*1.0 / AB*1.0\nyearID\n\n\n\n\n0\naddybo01\n3\n0.271186\n1871\n\n\n\n\n\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q1 chart .cell execution_count=4}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q1 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=5}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-2",
    "href": "Projects/project4.html#questiontask-2",
    "title": "Client Report - Project 4",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nCOPY PASTE QUESTION|TASK 2 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q2 chart .cell execution_count=7}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q2 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=8}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-3",
    "href": "Projects/project4.html#questiontask-3",
    "title": "Client Report - Project 4",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nCOPY PASTE QUESTION|TASK 3 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q3 chart .cell execution_count=10}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q3 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=11}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/study.html",
    "href": "Projects/study.html",
    "title": "Kevin Correia Data Science Portfolio",
    "section": "",
    "text": "title: “Client Report - Project 1” subtitle: “Course DS 250” author: “Kevin Correia” format: html: self-contained: true page-layout: full title-block-banner: true toc: true toc-depth: 3 toc-location: body number-sections: false html-math-method: katex code-fold: true code-summary: “Show the code” code-overflow: wrap code-copy: hover code-tools: source: false toggle: true caption: See code execute: warning: false\n\n\ncon = sqlite3.connect(\"lahmansbaseballdb.sqlite\")\n\n\nquery= \"\"\"\nselect sum(yearID), name from \nteams\nwhere yearID &lt;&gt; 1871\ngroup by name\nORDER BY sum(yearID) desc\n\n\n\n\"\"\"\n\ndf = pd.read_sql_query(query, con)\ndf\n\n\n\n\n\n\n\n\nsum(yearID)\nname\n\n\n\n\n0\n252195\nPittsburgh Pirates\n\n\n1\n251736\nCincinnati Reds\n\n\n2\n250198\nPhiladelphia Phillies\n\n\n3\n235140\nSt. Louis Cardinals\n\n\n4\n233240\nDetroit Tigers\n\n\n...\n...\n...\n\n\n132\n1872\nWashington Olympics\n\n\n133\n1872\nTroy Haymakers\n\n\n134\n1872\nMiddletown Mansfields\n\n\n135\n1872\nCleveland Forest Citys\n\n\n136\n1872\nBrooklyn Eckfords\n\n\n\n\n137 rows × 2 columns\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Kevin Correia",
    "section": "",
    "text": "Kevin Correia\n\n\nSkills\n\n\nPython\n\n\nFront-end Development\n\n\nTeamwork\n\n\nTrilingual: English, Spanish and Portuguese\n\n\nJava\n\n\nC#\n\n\n\n\nExperience\nAdministration and IT Census Agent\nIBGE (Brazilian Institute of Geography and Statistics)\n\n\nEducation\nBachelor of Science in Computer Science (In progress)\nBrigham Young University – Idaho\nCertificate - Web and Computer Programming Brigham Young University – Idaho\nDuring this certification I developed skills in functional programming (using Python), Front-End development (HTML, CSS and JS), and Object-Oriented Programming (using C#).\n\n\n\n\n Back to top"
  }
]